{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EECS 731 Project 5: World Wide Products Inc.\n",
    "\n",
    "In this project, I will be reading from a dataset of [product demands](https://www.kaggle.com/felixzhao/productdemandforecasting) and performing Time Series forecasting with the goal of predicting the future demand for the most commonly ordered product. In particular, I will perform forecasting across two different time frames:\n",
    "\n",
    "- The monthly product demand over multiple years (i.e. Year+Month combination), and\n",
    "- The annual product demand on a per-day basis (i.e. Month+Day combination).\n",
    "\n",
    "Due to the size of the original dataset, I do not include in the data/ directory. I will, however, save the processed dataset I create and use to the data/processed/ directory.\n",
    "\n",
    "### Python Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from math import sqrt\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create *sklearn* Objects\n",
    "\n",
    "To reduce the dataset values that will be evaluated later, I use a label encoder. In this case, I don't perform column normalization(s) as the Gradient Boosting model tested can't handle continuous inputs/outputs.\n",
    "\n",
    "I also employ the TimeSeriesSplit object in order to create train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "tscv = TimeSeriesSplit(n_splits=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Time Series Models\n",
    "\n",
    "In this project, I test the following three models:\n",
    "\n",
    "- Linear Regression\n",
    "- Gradient Boosting\n",
    "- Neural Network (MLP)\n",
    "\n",
    "For the Neural Network model, I arbitrarily set the number of max iterations to 100,000 so that the model can converge (I originally had it at 10,000 iterations but found that the model was still unable to converge in some instances)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "linearReg_model = LinearRegression()\n",
    "gradBoost_model = GradientBoostingClassifier()\n",
    "neuralNetwork_model = MLPRegressor(max_iter=100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the Raw Dataset\n",
    "\n",
    "In the process of reading the original dataset, I also remove any entries/rows that contain empty values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product_Code</th>\n",
       "      <th>Warehouse</th>\n",
       "      <th>Product_Category</th>\n",
       "      <th>Date</th>\n",
       "      <th>Order_Demand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Product_0993</td>\n",
       "      <td>Whse_J</td>\n",
       "      <td>Category_028</td>\n",
       "      <td>2012/7/27</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Product_0979</td>\n",
       "      <td>Whse_J</td>\n",
       "      <td>Category_028</td>\n",
       "      <td>2012/1/19</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Product_0979</td>\n",
       "      <td>Whse_J</td>\n",
       "      <td>Category_028</td>\n",
       "      <td>2012/2/3</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Product_0979</td>\n",
       "      <td>Whse_J</td>\n",
       "      <td>Category_028</td>\n",
       "      <td>2012/2/9</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Product_0979</td>\n",
       "      <td>Whse_J</td>\n",
       "      <td>Category_028</td>\n",
       "      <td>2012/3/2</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048570</th>\n",
       "      <td>Product_1791</td>\n",
       "      <td>Whse_J</td>\n",
       "      <td>Category_006</td>\n",
       "      <td>2016/4/27</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048571</th>\n",
       "      <td>Product_1974</td>\n",
       "      <td>Whse_J</td>\n",
       "      <td>Category_006</td>\n",
       "      <td>2016/4/27</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048572</th>\n",
       "      <td>Product_1787</td>\n",
       "      <td>Whse_J</td>\n",
       "      <td>Category_006</td>\n",
       "      <td>2016/4/28</td>\n",
       "      <td>2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048573</th>\n",
       "      <td>Product_0901</td>\n",
       "      <td>Whse_J</td>\n",
       "      <td>Category_023</td>\n",
       "      <td>2016/10/7</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048574</th>\n",
       "      <td>Product_0704</td>\n",
       "      <td>Whse_J</td>\n",
       "      <td>Category_001</td>\n",
       "      <td>2016/6/27</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1037336 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Product_Code Warehouse Product_Category       Date Order_Demand\n",
       "0        Product_0993    Whse_J     Category_028  2012/7/27         100 \n",
       "1        Product_0979    Whse_J     Category_028  2012/1/19         500 \n",
       "2        Product_0979    Whse_J     Category_028   2012/2/3         500 \n",
       "3        Product_0979    Whse_J     Category_028   2012/2/9         500 \n",
       "4        Product_0979    Whse_J     Category_028   2012/3/2         500 \n",
       "...               ...       ...              ...        ...          ...\n",
       "1048570  Product_1791    Whse_J     Category_006  2016/4/27        1000 \n",
       "1048571  Product_1974    Whse_J     Category_006  2016/4/27           1 \n",
       "1048572  Product_1787    Whse_J     Category_006  2016/4/28        2500 \n",
       "1048573  Product_0901    Whse_J     Category_023  2016/10/7          50 \n",
       "1048574  Product_0704    Whse_J     Category_001  2016/6/27           4 \n",
       "\n",
       "[1037336 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demand_list = pd.read_csv(\"../data/raw/demand.csv\").dropna()\n",
    "demand_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting a Dataset for the Most Ordered Product\n",
    "\n",
    "To find the most commonly ordered product (i.e. the product with the most rows in the dataset), I count the number of instances for each unique product code. Once found, I then extract the Date and Order_Demand columns only as the remaining columns (Warehouse, Product_Code, etc.) all contain the same respective value. As such, they wouldn't be helpful for predicting future demand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "product = demand_list[\"Product_Code\"].value_counts().keys()[0]\n",
    "product_list = demand_list[demand_list[\"Product_Code\"]==product]\n",
    "product_list = product_list.loc[:,(\"Date\",\"Order_Demand\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Desired Timeframes\n",
    "\n",
    "In the original dataset, the dates for each order are delimited by a \"/\" characeter. With this, I separate the dates into three different columns for the Year, Month and Day, respectively. In creating the Month and Day columns, I ensure all entries have two digits so that the combined datasets I create can remain in chronological order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_lists = product_list[\"Date\"].str.split(\"/\", expand=True)\n",
    "years = date_lists[0]\n",
    "months = date_lists[1].str.zfill(2)\n",
    "days = date_lists[2].str.zfill(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I then combine the three columns into two new columns, one for each of the desired time frames detailed above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "276        201204\n",
       "282        201205\n",
       "289        201206\n",
       "292        201207\n",
       "296        201208\n",
       "            ...  \n",
       "1046514    201610\n",
       "1046515    201609\n",
       "1046516    201611\n",
       "1046517    201612\n",
       "1046518    201612\n",
       "Length: 16936, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year_month = pd.to_numeric(years+months)\n",
    "year_month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "276         418\n",
       "282         521\n",
       "289         626\n",
       "292         717\n",
       "296         824\n",
       "           ... \n",
       "1046514    1003\n",
       "1046515     916\n",
       "1046516    1101\n",
       "1046517    1201\n",
       "1046518    1209\n",
       "Length: 16936, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "month_day = pd.to_numeric(months+days)\n",
    "month_day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that, without the additional 0 for single digit months and days, the combined datasets wouldn't be chronological, hence why the two digit minimum is necessary.\n",
    "\n",
    "### Creating the Processed Dataset\n",
    "\n",
    "Before creating a new dataframe, one final step that needs to be done is removing parentheses characters from the orders column as some entries contain them, thus preventing the column from being converted to any numeric type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "276         80000\n",
       "282         70000\n",
       "289         80000\n",
       "292        100000\n",
       "296        100000\n",
       "            ...  \n",
       "1046514     20000\n",
       "1046515     10000\n",
       "1046516     30000\n",
       "1046517     20000\n",
       "1046518     20000\n",
       "Name: Order_Demand, Length: 16936, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orders = product_list[\"Order_Demand\"].str.replace(r\"\\(\",\"\")\n",
    "orders = orders.str.replace(r\"\\)\",\"\")\n",
    "orders = pd.to_numeric(orders)\n",
    "orders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once done, I then create a new processed dataset with all of the desired features and orders which I then save to the datasets/processed/ directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Year+Month</th>\n",
       "      <th>Month+Day</th>\n",
       "      <th>Order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>2012</td>\n",
       "      <td>04</td>\n",
       "      <td>18</td>\n",
       "      <td>201204</td>\n",
       "      <td>418</td>\n",
       "      <td>80000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>2012</td>\n",
       "      <td>05</td>\n",
       "      <td>21</td>\n",
       "      <td>201205</td>\n",
       "      <td>521</td>\n",
       "      <td>70000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>2012</td>\n",
       "      <td>06</td>\n",
       "      <td>26</td>\n",
       "      <td>201206</td>\n",
       "      <td>626</td>\n",
       "      <td>80000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>2012</td>\n",
       "      <td>07</td>\n",
       "      <td>17</td>\n",
       "      <td>201207</td>\n",
       "      <td>717</td>\n",
       "      <td>100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>2012</td>\n",
       "      <td>08</td>\n",
       "      <td>24</td>\n",
       "      <td>201208</td>\n",
       "      <td>824</td>\n",
       "      <td>100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1046514</th>\n",
       "      <td>2016</td>\n",
       "      <td>10</td>\n",
       "      <td>03</td>\n",
       "      <td>201610</td>\n",
       "      <td>1003</td>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1046515</th>\n",
       "      <td>2016</td>\n",
       "      <td>09</td>\n",
       "      <td>16</td>\n",
       "      <td>201609</td>\n",
       "      <td>916</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1046516</th>\n",
       "      <td>2016</td>\n",
       "      <td>11</td>\n",
       "      <td>01</td>\n",
       "      <td>201611</td>\n",
       "      <td>1101</td>\n",
       "      <td>30000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1046517</th>\n",
       "      <td>2016</td>\n",
       "      <td>12</td>\n",
       "      <td>01</td>\n",
       "      <td>201612</td>\n",
       "      <td>1201</td>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1046518</th>\n",
       "      <td>2016</td>\n",
       "      <td>12</td>\n",
       "      <td>09</td>\n",
       "      <td>201612</td>\n",
       "      <td>1209</td>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16936 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Year Month Day  Year+Month  Month+Day   Order\n",
       "276      2012    04  18      201204        418   80000\n",
       "282      2012    05  21      201205        521   70000\n",
       "289      2012    06  26      201206        626   80000\n",
       "292      2012    07  17      201207        717  100000\n",
       "296      2012    08  24      201208        824  100000\n",
       "...       ...   ...  ..         ...        ...     ...\n",
       "1046514  2016    10  03      201610       1003   20000\n",
       "1046515  2016    09  16      201609        916   10000\n",
       "1046516  2016    11  01      201611       1101   30000\n",
       "1046517  2016    12  01      201612       1201   20000\n",
       "1046518  2016    12  09      201612       1209   20000\n",
       "\n",
       "[16936 rows x 6 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_dataset = pd.DataFrame({\"Year\":years,\"Month\":months,\"Day\":days,\"Year+Month\":year_month,\"Month+Day\":month_day,\"Order\":orders})\n",
    "product_dataset.to_csv(\"../data/processed/product_dataset.csv\")\n",
    "product_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Timeframe 1: Year+Month\n",
    "\n",
    "In order to perform Time Series forecasting for the Year+Month combination, I perform the following steps:\n",
    "\n",
    "- Retrieve the Year+Month and Order columns into two separate datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year+Month</th>\n",
       "      <th>Order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>201201</td>\n",
       "      <td>8911000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>201202</td>\n",
       "      <td>8131000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>201203</td>\n",
       "      <td>7775000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>201204</td>\n",
       "      <td>8960000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>201205</td>\n",
       "      <td>8475000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>201609</td>\n",
       "      <td>6960000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>201610</td>\n",
       "      <td>7727000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>201611</td>\n",
       "      <td>8814000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>201612</td>\n",
       "      <td>5653000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>201701</td>\n",
       "      <td>100000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Year+Month    Order\n",
       "0       201201  8911000\n",
       "1       201202  8131000\n",
       "2       201203  7775000\n",
       "3       201204  8960000\n",
       "4       201205  8475000\n",
       "..         ...      ...\n",
       "56      201609  6960000\n",
       "57      201610  7727000\n",
       "58      201611  8814000\n",
       "59      201612  5653000\n",
       "60      201701   100000\n",
       "\n",
       "[61 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ym_dataset = product_dataset.groupby(\"Year+Month\", as_index=False).agg({\"Order\":\"sum\"}) \n",
    "ym_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ym_feature = ym_dataset[\"Year+Month\"]\n",
    "ym_order = ym_dataset[\"Order\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Perform label encoding on each dataset. Since the Year+Month column is only a single feature, I also perform a reshape to add a necessary 2nd dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ym_feature = encoder.fit_transform(ym_feature).reshape(-1,1)\n",
    "ym_order = encoder.fit_transform(ym_order)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Perform Time Series forecasting with each of the models listed above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression: -1.49 (2.28)\n",
      "Gradient Boosting: -0.67 (0.74)\n",
      "Neural Network: -4.39 (8.24)\n"
     ]
    }
   ],
   "source": [
    "test = cross_val_score(linearReg_model, ym_feature, ym_order.ravel(), cv=tscv, scoring='r2')\n",
    "print(\"Linear Regression: {:.2f} ({:.2f})\".format(test.mean(), test.std()))\n",
    "\n",
    "test = cross_val_score(gradBoost_model, ym_feature, ym_order.ravel(), cv=tscv, scoring='r2')\n",
    "print(\"Gradient Boosting: {:.2f} ({:.2f})\".format(test.mean(), test.std()))\n",
    "\n",
    "test = cross_val_score(neuralNetwork_model, ym_feature, ym_order.ravel(), cv=tscv, scoring='r2')\n",
    "print(\"Neural Network: {:.2f} ({:.2f})\".format(test.mean(), test.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Timeframe 2: Month+Day\n",
    "\n",
    "In order to perform Time Series forecasting for the Month+Day combination, I perform the same steps and the first timeframe, but I retrieve the Month+Day column in the initial step instead of the Year+Month column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month+Day</th>\n",
       "      <th>Order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>105</td>\n",
       "      <td>1812000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>106</td>\n",
       "      <td>2507000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>107</td>\n",
       "      <td>1760000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>108</td>\n",
       "      <td>2709000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>109</td>\n",
       "      <td>618000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>1224</td>\n",
       "      <td>1130000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>1225</td>\n",
       "      <td>839000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>1226</td>\n",
       "      <td>1588000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>1227</td>\n",
       "      <td>286000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>1228</td>\n",
       "      <td>647000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>353 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Month+Day    Order\n",
       "0          105  1812000\n",
       "1          106  2507000\n",
       "2          107  1760000\n",
       "3          108  2709000\n",
       "4          109   618000\n",
       "..         ...      ...\n",
       "348       1224  1130000\n",
       "349       1225   839000\n",
       "350       1226  1588000\n",
       "351       1227   286000\n",
       "352       1228   647000\n",
       "\n",
       "[353 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md_dataset = product_dataset.groupby(\"Month+Day\", as_index=False).agg({\"Order\":\"sum\"}) \n",
    "md_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "md_feature = md_dataset[\"Month+Day\"]\n",
    "md_order = md_dataset[\"Order\"]\n",
    "md_feature = encoder.fit_transform(md_feature).reshape(-1,1)\n",
    "md_order = encoder.fit_transform(md_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression: -0.11 (0.07)\n",
      "Gradient Boosting: -0.36 (0.48)\n",
      "Neural Network: -0.38 (0.42)\n"
     ]
    }
   ],
   "source": [
    "test = cross_val_score(linearReg_model, md_feature, md_order.ravel(), cv=tscv, scoring='r2')\n",
    "print(\"Linear Regression: {:.2f} ({:.2f})\".format(test.mean(), test.std()))\n",
    "\n",
    "test = cross_val_score(gradBoost_model, md_feature, md_order.ravel(), cv=tscv, scoring='r2')\n",
    "print(\"Gradient Boosting: {:.2f} ({:.2f})\".format(test.mean(), test.std()))\n",
    "\n",
    "test = cross_val_score(neuralNetwork_model, md_feature, md_order.ravel(), cv=tscv, scoring='r2')\n",
    "print(\"Neural Network: {:.2f} ({:.2f})\".format(test.mean(), test.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "As can be seen in both of the timeframes evaluated, no single model was the best across the board. For the first timeframe, the Gradient Boosting model had the best performance whereas the Linear Regression Model had the best performance for the second timeframe. The Neural Network model, though, had extremely variable performance. On a per-model basis, the reasons for such behavior is likely due to the following:\n",
    "\n",
    "- For the Linear Regression model, it likely performed better in the second timeframe than the first one because there was less of a chronological dependency in the second timeframe. To be more specific, the second time frame tracked the average annual orders on a per-day basis instead of the order for each individual day across the given years. As such, there was a greater independence across the entries in the dataset for the second timeframe which then allowed for the Linear Regression model to perform better.\n",
    "- For the Gradient Boosting model, it likely performed the best in the first dataframe as there was a relatively small number of entries in that dataset. As such, it may have been more likely for the model to iteratively progress to a global minimum as opposed to a local minimum, which would have been more probable with a larger dataset. That being said, the Gradient Boosting model also performed relatively well in the second dataframe as well. However, it's performance in that specific instance was overshadowed by the Linear Regression model.\n",
    "- For the Neural Network model, note that the performance was highly variable across both timeframes. Even though the above results show the model performing very poorly in the first timeframe and decently in the second timeframe, I found that the same behavior wasn't consistently replicated between runs (e.g. in other runs, the model would perform much better on the first timeframe than the second one). This is likely due to how the train and test sets and created when the model is evaluated as they may result in the model overfitting and, hence, having worse performance. \n",
    "\n",
    "In the end, depending on the specific timeframe that is being evaluated, different models may be more applicable than other. Namely, the Linear Regression and Gradient Boosting could both be used, with the Gradient Boosting model being slightly more general as it, on average, performed better across both time frames. On the other hand, of the three models I tested, the Neural Network model is the least effective solution for this specific problem as it isn't consistent enough to have any confidence it its results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
